{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_labels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPS+M7S/zhglFF5I6y7iuii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8bbf64adbe244c9cbbe66004d0a3ad28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d6f0a17e48d43ba846171ca6b921036",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea5fad42335c4b8681ab50fa5c023e0e",
              "IPY_MODEL_1754f043c19e408f9ce44101b5fd8432"
            ]
          }
        },
        "5d6f0a17e48d43ba846171ca6b921036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea5fad42335c4b8681ab50fa5c023e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a6e0727d9e54a7eaae1848b2c0653bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e937bf3f5a684320bb9f2151975e30ef"
          }
        },
        "1754f043c19e408f9ce44101b5fd8432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f801e93dcba425186f1311babb81986",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 50820295.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea726bf291884ceb87453c0a8e5db3ab"
          }
        },
        "0a6e0727d9e54a7eaae1848b2c0653bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e937bf3f5a684320bb9f2151975e30ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f801e93dcba425186f1311babb81986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea726bf291884ceb87453c0a8e5db3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalculatedContent/ww-phys_theory/blob/master/random_labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFc8V-S5diFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "cifar-10 dataset, with support for random labels\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "class CIFAR10RandomLabels(datasets.CIFAR10):\n",
        "  \"\"\"CIFAR10 dataset, with support for randomly corrupt labels.\n",
        "\n",
        "  Params\n",
        "  ------\n",
        "  corrupt_prob: float\n",
        "    Default 0.0. The probability of a label being replaced with\n",
        "    random label.\n",
        "  num_classes: int\n",
        "    Default 10. The number of classes in the dataset.\n",
        "  \"\"\"\n",
        "  def __init__(self, corrupt_prob=0.0, num_classes=10, **kwargs):\n",
        "    super(CIFAR10RandomLabels, self).__init__(**kwargs)\n",
        "    self.n_classes = num_classes\n",
        "    if corrupt_prob > 0:\n",
        "      self.corrupt_labels(corrupt_prob)\n",
        "\n",
        "  def corrupt_labels(self, corrupt_prob):\n",
        "    labels = np.array(self.train_labels if self.train else self.test_labels)\n",
        "    np.random.seed(12345)\n",
        "    mask = np.random.rand(len(labels)) <= corrupt_prob\n",
        "    rnd_labels = np.random.choice(self.n_classes, mask.sum())\n",
        "    labels[mask] = rnd_labels\n",
        "    # we need to explicitly cast the labels from npy.int64 to\n",
        "    # builtin int type, otherwise pytorch will fail...\n",
        "    labels = [int(x) for x in labels]\n",
        "\n",
        "    if self.train:\n",
        "      self.train_labels = labels\n",
        "    else:\n",
        "      self.test_labels = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BcnTobdeQLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wide Resnet model adapted from https://github.com/xternalz/WideResNet-pytorch\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "    self.relu1 = nn.ReLU(inplace=True)\n",
        "    self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                            padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "    self.relu2 = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                            padding=1, bias=False)\n",
        "    self.droprate = dropRate\n",
        "    self.equalInOut = (in_planes == out_planes)\n",
        "    self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                                                            padding=0, bias=False) or None\n",
        "\n",
        "  def forward(self, x):\n",
        "    if not self.equalInOut:\n",
        "      x = self.relu1(self.bn1(x))\n",
        "      out = self.conv1(x)\n",
        "    else:\n",
        "      out = self.conv1(self.relu1(self.bn1(x)))\n",
        "\n",
        "    if self.droprate > 0:\n",
        "      out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "    out = self.conv2(self.relu2(self.bn2(out)))\n",
        "    if not self.equalInOut:\n",
        "      return torch.add(self.convShortcut(x), out)\n",
        "    else:\n",
        "      return torch.add(x, out)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTFcdxbIeWSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetworkBlock(nn.Module):\n",
        "  def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "    super(NetworkBlock, self).__init__()\n",
        "    self.layer = self._make_layer(\n",
        "        block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "\n",
        "  def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "    layers = []\n",
        "    for i in range(nb_layers):\n",
        "        layers.append(block(i == 0 and in_planes or out_planes,\n",
        "                            out_planes, i == 0 and stride or 1, dropRate))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6paAX6XyeaJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WideResNet(nn.Module):\n",
        "  def __init__(self, depth, num_classes, widen_factor=1, drop_rate=0.0, init_scale=1.0):\n",
        "    super(WideResNet, self).__init__()\n",
        "\n",
        "    nChannels = [16, 16 * widen_factor,\n",
        "                  32 * widen_factor, 64 * widen_factor]\n",
        "    assert((depth - 4) % 6 == 0)\n",
        "    n = (depth - 4) // 6\n",
        "    block = BasicBlock\n",
        "    # 1st conv before any network block\n",
        "    self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
        "                            padding=1, bias=False)\n",
        "    # 1st block\n",
        "    self.block1 = NetworkBlock(\n",
        "        n, nChannels[0], nChannels[1], block, 1, drop_rate)\n",
        "    # 2nd block\n",
        "    self.block2 = NetworkBlock(\n",
        "        n, nChannels[1], nChannels[2], block, 2, drop_rate)\n",
        "    # 3rd block\n",
        "    self.block3 = NetworkBlock(\n",
        "        n, nChannels[2], nChannels[3], block, 2, drop_rate)\n",
        "    # global average pooling and classifier\n",
        "    self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.fc = nn.Linear(nChannels[3], num_classes)\n",
        "    self.nChannels = nChannels[3]\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, init_scale * math.sqrt(2. / n))\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "        size = m.weight.size()\n",
        "        fan_out = size[0] # number of rows\n",
        "        fan_in = size[1] # number of columns\n",
        "        variance = math.sqrt(2.0/(fan_in + fan_out))\n",
        "        m.weight.data.normal_(0.0, init_scale * variance)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.forward_repr(x)\n",
        "    return self.fc(out)\n",
        "\n",
        "  def forward_repr(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.block1(out)\n",
        "    out = self.block2(out)\n",
        "    out = self.block3(out)\n",
        "    out = self.relu(self.bn1(out))\n",
        "    out = F.avg_pool2d(out, 8)\n",
        "    out = out.view(-1, self.nChannels)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npExgFazefiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "\n",
        "\n",
        "\n",
        "def get_data_loaders(args, shuffle_train=True):\n",
        "  if args.data == 'cifar10':\n",
        "    normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "    if args.data_augmentation:\n",
        "      transform_train = transforms.Compose([\n",
        "          transforms.RandomCrop(32, padding=4),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.ToTensor(),\n",
        "          normalize,\n",
        "          ])\n",
        "    else:\n",
        "      transform_train = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          normalize,\n",
        "          ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "        ])\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        CIFAR10RandomLabels(root='./data', train=True, download=True,\n",
        "                            transform=transform_train, num_classes=args.num_classes,\n",
        "                            corrupt_prob=args.label_corrupt_prob),\n",
        "        batch_size=args.batch_size, shuffle=shuffle_train, **kwargs)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        CIFAR10RandomLabels(root='./data', train=False,\n",
        "                            transform=transform_test, num_classes=args.num_classes,\n",
        "                            corrupt_prob=args.label_corrupt_prob),\n",
        "        batch_size=args.batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "  else:\n",
        "    raise Exception('Unsupported dataset: {0}'.format(args.data))\n",
        "\n",
        "\n",
        "def get_model(args):\n",
        "  # create model\n",
        "  if args.arch == 'wide-resnet':\n",
        "    model = WideResNet(args.wrn_depth, args.num_classes,\n",
        "                                        args.wrn_widen_factor,\n",
        "                                        drop_rate=args.wrn_droprate)\n",
        "  elif args.arch == 'mlp':\n",
        "    n_units = [int(x) for x in args.mlp_spec.split('x')] # hidden dims\n",
        "    n_units.append(args.num_classes)  # output dim\n",
        "    n_units.insert(0, 32*32*3)        # input dim\n",
        "    model = MLP(n_units)\n",
        "\n",
        "  # for training on multiple GPUs.\n",
        "  # Use CUDA_VISIBLE_DEVICES=0,1 to specify which GPUs to use\n",
        "    model = torch.nn.DataParallel(model).cuda()\n",
        "    model = model.cuda()\n",
        "\n",
        "  return model\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YukzX9cexwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(args, model, train_loader, val_loader,\n",
        "                start_epoch=None, epochs=None):\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "  # define loss function (criterion) and pptimizer\n",
        "  criterion = nn.CrossEntropyLoss()#.cuda()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), args.learning_rate,\n",
        "                              momentum=args.momentum,\n",
        "                              weight_decay=args.weight_decay)\n",
        "\n",
        "  start_epoch = start_epoch or 0\n",
        "  epochs = epochs or args.epochs\n",
        "\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    adjust_learning_rate(optimizer, epoch, args)\n",
        "\n",
        "    # train for one epoch\n",
        "    tr_loss, tr_prec1 = train_epoch(train_loader, model, criterion, optimizer, epoch, args)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    val_loss, val_prec1 = validate_epoch(val_loader, model, criterion, epoch, args)\n",
        "\n",
        "    if args.eval_full_trainset:\n",
        "      tr_loss, tr_prec1 = validate_epoch(train_loader, model, criterion, epoch, args)\n",
        "\n",
        "    logging.info('%03d: Acc-tr: %6.2f, Acc-val: %6.2f, L-tr: %6.4f, L-val: %6.4f',\n",
        "                 epoch, tr_prec1, val_prec1, tr_loss, val_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BuXaT1SfOWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(train_loader, model, criterion, optimizer, epoch, args):\n",
        "  \"\"\"Train for one epoch on the training set\"\"\"\n",
        "  batch_time = AverageMeter()\n",
        "  losses = AverageMeter()\n",
        "  top1 = AverageMeter()\n",
        "\n",
        "  # switch to train mode\n",
        "  model.train()\n",
        "\n",
        "  for i, (input, target) in enumerate(train_loader):\n",
        "    #target = target.cuda(async=True)\n",
        "    #input = input.cuda()\n",
        "    input_var = torch.autograd.Variable(input)\n",
        "    target_var = torch.autograd.Variable(target)\n",
        "\n",
        "    # compute output\n",
        "    output = model(input_var)\n",
        "    loss = criterion(output, target_var)\n",
        "\n",
        "    # measure accuracy and record loss\n",
        "    prec1 = accuracy(output.data, target, topk=(1,))[0] \n",
        "    losses.update(loss.item(), input.size(0))\n",
        "    top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "    # compute gradient and do SGD step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return losses.avg, top1.avg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGn9S8x2fRF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_epoch(val_loader, model, criterion, epoch, args):\n",
        "  \"\"\"Perform validation on the validation set\"\"\"\n",
        "  batch_time = AverageMeter()\n",
        "  losses = AverageMeter()\n",
        "  top1 = AverageMeter()\n",
        "\n",
        "  # switch to evaluate mode\n",
        "  model.eval()\n",
        "\n",
        "  for i, (input, target) in enumerate(val_loader):\n",
        "    #target = target.cuda(async=True)\n",
        "    #input = input.cuda()\n",
        "    input_var = torch.autograd.Variable(input, volatile=True)\n",
        "    target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "    # compute output\n",
        "    output = model(input_var)\n",
        "    loss = criterion(output, target_var)\n",
        "\n",
        "    # measure accuracy and record loss\n",
        "    prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "    losses.update(loss.item(), input.size(0))\n",
        "    top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "  return losses.avg, top1.avg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03mxnc3ZfT7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "  \"\"\"Computes and stores the average and current value\"\"\"\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val * n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L66xQZCufWTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "  \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
        "  lr = args.learning_rate * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
        "  for param_group in optimizer.param_groups:\n",
        "      param_group['lr'] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLtBJs_qfYVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "  \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "  maxk = max(topk)\n",
        "  batch_size = target.size(0)\n",
        "\n",
        "  _, pred = output.topk(maxk, 1, True, True)\n",
        "  pred = pred.t()\n",
        "  correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "  res = []\n",
        "  for k in topk:\n",
        "      correct_k = correct[:k].view(-1).float().sum(0)\n",
        "      res.append(correct_k.mul_(100.0 / batch_size))\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ie839rCfZ7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_logging(args):\n",
        "  import datetime\n",
        "  exp_dir = os.path.join('runs', args.exp_name)\n",
        "  if not os.path.isdir(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "  log_fn = os.path.join(exp_dir, \"LOG.{0}.txt\".format(datetime.date.today().strftime(\"%y%m%d\")))\n",
        "  logging.basicConfig(filename=log_fn, filemode='w', level=logging.DEBUG)\n",
        "  # also log into console\n",
        "  console = logging.StreamHandler()\n",
        "  console.setLevel(logging.INFO)\n",
        "  logging.getLogger('').addHandler(console)\n",
        "  print('Logging into %s...' % exp_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOMOKprttMkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--eval-full-trainset', type=bool, default=True,\n",
        "                    help='Whether to re-evaluate the full train set on a fixed model, or simply ' +\n",
        "                    'report the running average of training statistics')\n",
        "\n",
        "parser.add_argument('--command', default='train', choices=['train'])\n",
        "parser.add_argument('--data', default='cifar10', choices=['cifar10'])\n",
        "parser.add_argument('--num-classes', type=int, default=10)\n",
        "parser.add_argument('--data-augmentation', type=bool, default=False)\n",
        "parser.add_argument('--label-corrupt-prob', type=float, default=0.0)\n",
        "\n",
        "parser.add_argument('--batch-size', type=int, default=16)\n",
        "parser.add_argument('--epochs', type=int, default=300)\n",
        "parser.add_argument('--learning-rate', type=float, default=0.01)\n",
        "parser.add_argument('--momentum', type=float, default=0.9)\n",
        "parser.add_argument('--weight-decay', type=float, default=1e-4)\n",
        "\n",
        "parser.add_argument('--arch', default='wide-resnet', choices=['wide-resnet', 'mlp'])\n",
        "\n",
        "parser.add_argument('--wrn-depth', type=int, default=28)\n",
        "parser.add_argument('--wrn-widen-factor', type=int, default=1)\n",
        "parser.add_argument('--wrn-droprate', type=float, default=0.0)\n",
        "\n",
        "parser.add_argument('--mlp-spec', default='512',\n",
        "                    help='mlp spec: e.g. 512x128x512 indicates 3 hidden layers')\n",
        "\n",
        "parser.add_argument('--name', default='', help='Experiment name')\n",
        "\n",
        "\n",
        "def format_experiment_name(args):\n",
        "  name = args.name\n",
        "  if name != '':\n",
        "    name += '_'\n",
        "\n",
        "  name += args.data + '_'\n",
        "  if args.label_corrupt_prob > 0:\n",
        "    name += 'corrupt%g_' % args.label_corrupt_prob\n",
        "\n",
        "  name += args.arch\n",
        "  if args.arch == 'wide-resnet':\n",
        "    dropmark = '' if args.wrn_droprate == 0 else ('-dr%g' % args.wrn_droprate)\n",
        "    name += '{0}-{1}{2}'.format(args.wrn_depth, args.wrn_widen_factor, dropmark)\n",
        "  elif args.arch == 'mlp':\n",
        "    name += args.mlp_spec\n",
        "\n",
        "  name += '_lr{0}_mmt{1}'.format(args.learning_rate, args.momentum)\n",
        "  if args.weight_decay > 0:\n",
        "    name += '_Wd{0}'.format(args.weight_decay)\n",
        "  else:\n",
        "    name += '_NoWd'\n",
        "  if not args.data_augmentation:\n",
        "    name += '_NoAug'\n",
        "\n",
        "  return name\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB7fUhN9fdlB",
        "colab_type": "code",
        "outputId": "c2cee536-507c-4820-a7b2-3d55310fd241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "args = parser.parse_args(\"\")\n",
        "args"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(arch='wide-resnet', batch_size=16, command='train', data='cifar10', data_augmentation=False, epochs=300, eval_full_trainset=True, label_corrupt_prob=0.0, learning_rate=0.01, mlp_spec='512', momentum=0.9, name='', num_classes=10, weight_decay=0.0001, wrn_depth=28, wrn_droprate=0.0, wrn_widen_factor=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFq5SCP_0fPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args.exp_name = format_experiment_name(args)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzav--FVtcc9",
        "colab_type": "code",
        "outputId": "939af4f5-cd23-4e06-9427-651f0ac8567c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " setup_logging(args)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging into runs/cifar10_wide-resnet28-1_lr0.01_mmt0.9_Wd0.0001_NoAug...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ov6XNG30VqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRwhyzaf2SA8",
        "colab_type": "code",
        "outputId": "9a969d1e-b29b-49d2-86fb-1e6ca7edc2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "8bbf64adbe244c9cbbe66004d0a3ad28",
            "5d6f0a17e48d43ba846171ca6b921036",
            "ea5fad42335c4b8681ab50fa5c023e0e",
            "1754f043c19e408f9ce44101b5fd8432",
            "0a6e0727d9e54a7eaae1848b2c0653bc",
            "e937bf3f5a684320bb9f2151975e30ef",
            "3f801e93dcba425186f1311babb81986",
            "ea726bf291884ceb87453c0a8e5db3ab"
          ]
        }
      },
      "source": [
        "train_loader, val_loader = get_data_loaders(args, shuffle_train=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bbf64adbe244c9cbbe66004d0a3ad28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VkHYFhW0qOG",
        "colab_type": "code",
        "outputId": "056afbf4-acc4-4fa3-bec4-09189f074cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train_model(args, model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "000: Acc-tr:  64.58, Acc-val:  63.59, L-tr: 0.9940, L-val: 1.0248\n",
            "001: Acc-tr:  73.01, Acc-val:  70.62, L-tr: 0.7791, L-val: 0.8576\n",
            "002: Acc-tr:  79.62, Acc-val:  76.31, L-tr: 0.5867, L-val: 0.6949\n",
            "003: Acc-tr:  83.24, Acc-val:  79.28, L-tr: 0.4840, L-val: 0.6050\n",
            "004: Acc-tr:  84.97, Acc-val:  80.20, L-tr: 0.4381, L-val: 0.5886\n",
            "005: Acc-tr:  86.47, Acc-val:  80.76, L-tr: 0.3887, L-val: 0.5665\n",
            "006: Acc-tr:  88.66, Acc-val:  82.35, L-tr: 0.3275, L-val: 0.5388\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfs-iqqK0wPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model.save_state_dict('model.pt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj26rr7JC5AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}