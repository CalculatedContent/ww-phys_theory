{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compare_Jacobian-Diag.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNHNYs7peXSSQgryimc6g67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalculatedContent/ww-phys_theory/blob/master/Compare_Jacobian_Diag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5SZBw7V8d8r",
        "colab_type": "text"
      },
      "source": [
        "### Compare Diagonal Jacobian on ResNet 1 batch\n",
        "\n",
        "Why is my data different from Johns ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah8bp3K48eum",
        "colab_type": "code",
        "outputId": "28516e2b-5357-421c-9b92-9c3e824f7269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5.0+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision==0.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu101) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSlymHmAIph5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thismodel = 'resnet20_cifar10'\n",
        "inum_start = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZplJz8WqCkD",
        "colab_type": "code",
        "outputId": "b336ad5c-cc56-47cf-8335-c93c78aaebd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=f89b63f6bc159fb601861d8362f92d1ca970d1405b720f25d4f61ac34ca41ab2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBc9xEiMgn5N",
        "colab_type": "code",
        "outputId": "49427605-5610-471b-ab1d-ccc6046b5097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install pytorchcv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorchcv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/be/0bcd80dfc0d64e75ceb67836385402fece3c3b964c349172a21358813b25/pytorchcv-0.0.58-py2.py3-none-any.whl (435kB)\n",
            "\r\u001b[K     |▊                               | 10kB 27.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 327kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 337kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 348kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 368kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 378kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 389kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 399kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 419kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 430kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 440kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorchcv) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorchcv) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (3.0.4)\n",
            "Installing collected packages: pytorchcv\n",
            "Successfully installed pytorchcv-0.0.58\n",
            "Collecting powerlaw\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/4e/3ceab890fafff8e78a5fd7f5340c232c38b21d181fcd32d7a31079db3646/powerlaw-1.4.6.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from powerlaw) (3.2.1)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->powerlaw) (1.12.0)\n",
            "Building wheels for collected packages: powerlaw\n",
            "  Building wheel for powerlaw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for powerlaw: filename=powerlaw-1.4.6-cp36-none-any.whl size=24787 sha256=145d1f884a4ec977e2534b9f726fe9baae4e3ac5efcd9fee398807c41d165b01\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/27/02/08d0e2865072bfd8d7c655e290521e3feca3fc22f1ac460601\n",
            "Successfully built powerlaw\n",
            "Installing collected packages: powerlaw\n",
            "Successfully installed powerlaw-1.4.6\n",
            "time: 6.66 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Phn2n_jEvO",
        "colab_type": "code",
        "outputId": "03b5e1a9-146b-46ae-832c-12863aa9ed75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install GPUtil\n",
        "import GPUtil\n",
        "\n",
        "GPUtil.showUtilization()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=ea3636c6830aa36e86424231b9c042d0553bf60b9dc42b18f2a4574160c6f2cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% |  0% |\n",
            "time: 3.52 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rBl2Oq6DQu9",
        "colab_type": "code",
        "outputId": "f93e608d-9626-408d-c503-2994c9b4e72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import math\n",
        "import copy\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: import: command not found\n",
            "time: 1.59 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y80VeTU_jcI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05167a0f-e38b-4d14-b745-e1a5fb2686e5"
      },
      "source": [
        "def get_data(batch_size=100, train_range=None, test_range=None):\n",
        "  normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "  transform_train = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          normalize])\n",
        "  transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize])\n",
        "  train_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=True, \n",
        "                                transform=transform_train,\n",
        "                                download=True)\n",
        "  test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=transform_test,\n",
        "                                download=True)  \n",
        "  \n",
        "  if train_range:\n",
        "      train_dataset = torch.utils.data.Subset(train_dataset, train_range)\n",
        "\n",
        "  if test_range:\n",
        "      teat_dataset = torch.utils.data.Subset(test_dataset, test_range)\n",
        "\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=4,\n",
        "                          shuffle=False)\n",
        "  test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size,\n",
        "                         num_workers=4,\n",
        "                         shuffle=False)\n",
        "  return train_dataset, test_dataset, train_loader, test_loader"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 12.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmtV_hb3ShMf",
        "colab_type": "text"
      },
      "source": [
        "### $J$ Jacobian (replaces native pytorch 1.5 code)\n",
        "\n",
        "Uses autograd \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3IWYa-PEPKn",
        "colab_type": "code",
        "outputId": "37f539bc-91ae-421c-8934-44e90bbb3d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.autograd.gradcheck import zero_gradients\n",
        "\n",
        "def fast_jacobian(inputs, output, batch_size, data_dim):\n",
        "\t\"\"\"\n",
        "\tinput: input for the function for which the Jacobian will\n",
        "\tcomputed. It will be batch_size*data_dim. Make sure that the\n",
        "\tinput is flagged as requires_grad=True with the torch.autograd.Variable\n",
        "\twrapper. \n",
        "\toutput: output of the function for which the Jacobian will\n",
        "\tbe computed. It will be batch_size*classes\n",
        "\treturn: Jacobian of dimension batch_size*classes*data_dim\n",
        "\t\"\"\"\n",
        "\tassert inputs.requires_grad\n",
        "\tprint(\"inputs: \",inputs.shape)\n",
        "\tnum_classes = output.size()[1] #0 index is batch\n",
        "\n",
        "\tjacobian = torch.zeros(num_classes, *inputs.size())\n",
        "\tgrad_output = torch.zeros(*output.size())\n",
        "\tif inputs.is_cuda:\n",
        "\t\tgrad_output = grad_output.cuda()\n",
        "\t\tjacobian = jacobian.cuda()\n",
        "\n",
        "\t#zero out gradients\n",
        "\t#compute gradient for one of the classes\n",
        "\tfor i in range(num_classes):\n",
        "\t\tzero_gradients(inputs)\n",
        "\t\tgrad_output.zero_()\n",
        "\t\tgrad_output[:,i] = 1\n",
        "\t\toutput.backward(grad_output, retain_graph=True)\n",
        "\t\tjacobian[i] = inputs.grad.data\n",
        "\n",
        "\tJ =  torch.transpose(jacobian, dim0=0, dim1=1)\n",
        "\tprint(\"fast J: \",J.shape, data_dim)\n",
        "\tJ = J.reshape(batch_size, data_dim)\n",
        " \n",
        "\treturn J\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 11.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cYoUS_mPlPs",
        "colab_type": "text"
      },
      "source": [
        "### Compare old and new diagonal;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlaD-n5OsIcO",
        "colab_type": "text"
      },
      "source": [
        "### ResNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT8SeVRcyv2R",
        "colab_type": "code",
        "outputId": "9a9088bc-42d4-425b-cddd-39f6a2f749cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import pytorchcv\n",
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "\n",
        "for modelname in pytorchcv.model_provider._models.keys():\n",
        "    if modelname.startswith('resnet') and modelname.endswith('cifar10'):\n",
        "        print(modelname)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resnet20_cifar10\n",
            "resnet56_cifar10\n",
            "resnet110_cifar10\n",
            "resnet164bn_cifar10\n",
            "resnet272bn_cifar10\n",
            "resnet542bn_cifar10\n",
            "resnet1001_cifar10\n",
            "resnet1202_cifar10\n",
            "time: 98.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1hvNREVTDkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ait1lWyqgbUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "504b63fc-a5ce-4402-91ac-f790dcfa95c2"
      },
      "source": [
        "num_classes= 10\n",
        "device = 'cuda:0'\n",
        "\n",
        "data_dim = 3*32*32\n",
        "\n",
        "model = ptcv_get_model(thismodel, pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "for batch_size in range(1,5):\n",
        "  print(\"batch size \", batch_size)\n",
        "  train_dataset, test_dataset, train_loader, test_loader = get_data(batch_size=batch_size)\n",
        "\n",
        "  for batch, data in enumerate(test_loader):\n",
        "    features, labels = data\n",
        "\n",
        "    inputs = features.to(device)\n",
        "    inputs.requires_grad=True\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    Jnew = fast_jacobian(inputs, outputs, batch_size, num_classes*data_dim)\n",
        "    j0new = Jnew.cpu().numpy()[0,:]\n",
        "\n",
        "    Jold = torch.autograd.functional.jacobian(model, inputs)\n",
        "    print(Jold.shape)\n",
        "    j0orig = Jold.cpu().numpy()[0,:,0,:,:,:]\n",
        "    \n",
        "    Jold = Jold.view(batch_size,num_classes*batch_size*data_dim)\n",
        "    j0old = Jold.cpu().numpy()[0,:]\n",
        "\n",
        "    print(\"||jnew|| \", np.linalg.norm(j0new))\n",
        "    print(\"||jorig|| \", np.linalg.norm(j0orig))\n",
        "    print(\"||jold|| \", np.linalg.norm(j0old))\n",
        "    print(\".   \")\n",
        "\n",
        "    break\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch size  1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "inputs:  torch.Size([1, 3, 32, 32])\n",
            "fast J:  torch.Size([1, 10, 3, 32, 32]) 30720\n",
            "torch.Size([1, 10, 1, 3, 32, 32])\n",
            "||jnew||  11.510124\n",
            "||jorig||  11.510125\n",
            "||jold||  11.510125\n",
            ".   \n",
            "batch size  2\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "inputs:  torch.Size([2, 3, 32, 32])\n",
            "fast J:  torch.Size([2, 10, 3, 32, 32]) 30720\n",
            "torch.Size([2, 10, 2, 3, 32, 32])\n",
            "||jnew||  5.987037\n",
            "||jorig||  12.755404\n",
            "||jold||  18.5789\n",
            ".   \n",
            "batch size  3\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "inputs:  torch.Size([3, 3, 32, 32])\n",
            "fast J:  torch.Size([3, 10, 3, 32, 32]) 30720\n",
            "torch.Size([3, 10, 3, 3, 32, 32])\n",
            "||jnew||  6.950019\n",
            "||jorig||  19.470583\n",
            "||jold||  27.521496\n",
            ".   \n",
            "batch size  4\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "inputs:  torch.Size([4, 3, 32, 32])\n",
            "fast J:  torch.Size([4, 10, 3, 32, 32]) 30720\n",
            "torch.Size([4, 10, 4, 3, 32, 32])\n",
            "||jnew||  6.722236\n",
            "||jorig||  14.487082\n",
            "||jold||  22.10092\n",
            ".   \n",
            "time: 7.57 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX6Zld31s5j4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}