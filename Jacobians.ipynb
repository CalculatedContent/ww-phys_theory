{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CalculatedContent/ww-phys_theory/blob/master/Jacobians.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ZOAvU6VYDKCC",
    "outputId": "32c2d40d-57f1-41ac-fae5-4f5c28f3113f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.5.0+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
      "Requirement already satisfied: torchvision==0.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (1.18.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu101) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "hZplJz8WqCkD",
    "outputId": "4a2ea27c-0eee-4404-8d5c-135f9b6c254d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-autotime\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
      "Building wheels for collected packages: ipython-autotime\n",
      "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=a1aa54f5099a897d1133b327cdad2287f9e0431d37ecbaa6bf802bb434ed9335\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
      "Successfully built ipython-autotime\n",
      "Installing collected packages: ipython-autotime\n",
      "Successfully installed ipython-autotime-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQGrAUZLSEy_"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2zo-pydFSFYR",
    "outputId": "e1cb6d4f-bbe8-4ebf-ef91-70862b276e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.06 ms\n"
     ]
    }
   ],
   "source": [
    "#!cd drive/'My Drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0rBl2Oq6DQu9",
    "outputId": "f82b7f22-1f10-4452-c6ea-084ae9eed25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self, n_units, init_scale=1.0):\n",
    "    super(MLP, self).__init__()\n",
    "\n",
    "    self._n_units = copy.copy(n_units)\n",
    "    self._layers = []\n",
    "    for i in range(1, len(n_units)):\n",
    "      layer = nn.Linear(n_units[i-1], n_units[i], bias=False)\n",
    "      variance = math.sqrt(2.0 / (n_units[i-1] + n_units[i]))\n",
    "      layer.weight.data.normal_(0.0, init_scale * variance)\n",
    "      self._layers.append(layer)\n",
    "\n",
    "      name = 'fc%d' % i\n",
    "      if i == len(n_units) - 1:\n",
    "        name = 'fc'  # the prediction layer is just called fc\n",
    "      self.add_module(name, layer)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, self._n_units[0])\n",
    "    out = self._layers[0](x)\n",
    "    for layer in self._layers[1:]:\n",
    "      out = F.relu(out)\n",
    "      out = layer(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kz2yG2YcKvCI",
    "outputId": "7a8bcbd4-cfbe-4191-8ebc-4bcfb9e3f8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.61 s\n"
     ]
    }
   ],
   "source": [
    "mlp_spec = '512'\n",
    "batch_size = 100\n",
    "n_units = [int(x) for x in mlp_spec.split('x')] # hidden dims\n",
    "n_units.append(10)  # output dim\n",
    "n_units.insert(0, 32*32*3)        # input dim\n",
    "model = MLP(n_units)\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XcXIRwl3NGhs",
    "outputId": "9f6a0b50-ef78-46dc-96c9-29499ebfc8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.4 ms\n"
     ]
    }
   ],
   "source": [
    "def get_data(batch_size=100):\n",
    "  normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "  transform_train = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          normalize])\n",
    "  transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize])\n",
    "  train_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=True, \n",
    "                                transform=transform_train,\n",
    "                                download=True)\n",
    "  test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=transform_test,\n",
    "                                download=True)  \n",
    "  train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "  test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=4,\n",
    "                         shuffle=False)\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLSkqV5rPoa-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "7f0RkdU7dx9t",
    "outputId": "538fc433-2c8b-48e9-f347-2d881fb694a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Building wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=55a88f9e251c4974fdb3865a3342b4f29ed4f4e46632d989739a9c9a95e98895\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  4% |\n",
      "time: 4.39 s\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil\n",
    "import GPUtil\n",
    "\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XZxB6zg8jXYu",
    "outputId": "82930170-9859-48da-a52c-e615cc68c1f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.6 ms\n"
     ]
    }
   ],
   "source": [
    "def jacobian_vector_mult(model, data_loader, vec, batch_size, num_classes=10, device='cuda:0', data_dim=3*32*32):\n",
    "  '''compute J(J*v)  matrix-vector Mv multiply,  M=JJ* , where J is the jacobian,'''\n",
    "\n",
    "  # compute J*v\n",
    "  Jvecs = []\n",
    "  model = model.to(\"cuda:0\")\n",
    "  \n",
    "  istart = 0\n",
    "  iend = istart + batch_size\n",
    "\n",
    "  for batch, data in enumerate(data_loader):\n",
    "    features, _ = data\n",
    "    features = features.to(device)\n",
    "\n",
    "    v = vec[istart:iend].to(device)\n",
    "    istart += batch_size\n",
    "    iend = istart + batch_size\n",
    "\n",
    "    J = torch.autograd.functional.jacobian(model, features)# create_graph=True)\n",
    "    J = J.view(batch_size,num_classes*batch_size*data_dim)\n",
    "    J = J.transpose_(0,1)\n",
    "    x = torch.mv(J,v).to('cpu')\n",
    "\n",
    "    del J\n",
    "    torch.cuda.empty_cache()\n",
    "    Jvecs.append(x)\n",
    "\n",
    "    del x\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  JJvec = None\n",
    "\n",
    "  # compute J(J*v)\n",
    "  for batch, data in enumerate(data_loader):\n",
    "    features, _ = data\n",
    "    features = features.to(device)\n",
    "\n",
    "    J = torch.autograd.functional.jacobian(model, features)\n",
    "    J = J.view(batch_size,num_classes*batch_size*data_dim)\n",
    "    Jvec = Jvecs[batch].to(device)\n",
    "    x = torch.mv(J, Jvec).to('cpu')\n",
    "\n",
    "    del J\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if JJvec is None:\n",
    "      JJvec = x\n",
    "    else:\n",
    "      JJvec = torch.cat((JJvec, x))\n",
    "\n",
    "    del x\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  del Jvecs\n",
    "\n",
    "  return JJvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "c007b43542fa4ee0890d1659d9382daf",
      "d912d31755e74aa8b1c2879b67e49e5e",
      "24d98895f91842deaafef1eb2d6c70cd",
      "6c5df6f7e0c84a8d934d85c05d45b4de",
      "38945f2115b848f78702807a5d42af41",
      "02495f41a17b448bbca9e8be8328154c",
      "df43ae87ee21434cb56bca9946fa8f92",
      "f66ac5d1927e46d3a1c8d5aea4ccf788"
     ]
    },
    "colab_type": "code",
    "id": "LqjXxvxEkrBD",
    "outputId": "7f58f571-427e-4aca-e845-3a8d5955adf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000]) tensor(1.0000)\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  4% |\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c007b43542fa4ee0890d1659d9382daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n",
      "time: 6.2 s\n"
     ]
    }
   ],
   "source": [
    "num_classes= 10\n",
    "batch_size = 100\n",
    "device = 'cuda:0'\n",
    "\n",
    "num_data = 50000\n",
    "v = torch.randn(num_data)  # generate random vectora\n",
    "v = v/torch.norm(v, p=2, dim=0)\n",
    "print(v.shape, torch.norm(v, p=2, dim=0))\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "train_loader, _ = get_data(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m4AMYCJvbpB7",
    "outputId": "b6a3ed4b-6ad1-44dd-ccae-cf3ace5efcce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 877 µs\n"
     ]
    }
   ],
   "source": [
    "#JJvec = jacobian_vector_mult(model, train_loader, v, batch_size)\n",
    "#plt.hist(JJvec, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DmtV_hb3ShMf"
   },
   "source": [
    "### $J^{T}J$ Diagonal elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ay4hgME-SgaV",
    "outputId": "84cbe2ca-1b47-4388-8bc7-844c1872b348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "def jacobian_diagonal(model, data_loader, batch_size, num_classes=10, device='cuda:0', data_dim=3*32*32):\n",
    "  '''compute J(J*v) diagnonal elements , where J is the jacobian,'''\n",
    "\n",
    "  # compute Jdiag\n",
    "  Jdiag = []\n",
    "  model = model.to(device)\n",
    "\n",
    "  for batch, data in enumerate(data_loader):\n",
    "    features, _ = data\n",
    "    features = features.to(device)\n",
    "\n",
    "    J = torch.autograd.functional.jacobian(model, features)# create_graph=True)\n",
    "    J = J.view(batch_size,num_classes*batch_size*data_dim)\n",
    "    Jt = J.clone().transpose_(0,1)\n",
    "    batch_diag = torch.mm(J,Jt).to('cpu')\n",
    "    del J, Jt\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for ib in range(batch_size):\n",
    "      Jdiag.append(batch_diag[ib, ib].to('cpu').numpy())\n",
    "\n",
    "    del batch_diag\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  return np.array(Jdiag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlaD-n5OsIcO"
   },
   "source": [
    "### ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "hUuQe4AoxCSW",
    "outputId": "7cc20216-ccb3-4a58-e934-0ddcb4e9dde8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorchcv\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/be/0bcd80dfc0d64e75ceb67836385402fece3c3b964c349172a21358813b25/pytorchcv-0.0.58-py2.py3-none-any.whl (435kB)\n",
      "\r",
      "\u001b[K     |▊                               | 10kB 20.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 20kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 30kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 40kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 51kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 61kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 71kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 81kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 92kB 3.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 102kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 112kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 122kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 133kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 143kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 153kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 163kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 174kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 184kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 194kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 204kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 215kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 225kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 235kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 245kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 256kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 266kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 276kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 286kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 296kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 307kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 317kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 327kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 337kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 348kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 358kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 368kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 378kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 389kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 399kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 409kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 419kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 430kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 440kB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorchcv) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorchcv) (1.18.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (1.24.3)\n",
      "Installing collected packages: pytorchcv\n",
      "Successfully installed pytorchcv-0.0.58\n",
      "time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "y2I-YKtSsHhr",
    "outputId": "72e82461-6730-40e5-a0a6-fdb32737dddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "import pytorchcv\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "UW-f_EPP2g9U",
    "outputId": "8aace506-0045-4737-eb74-c486929e87a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting powerlaw\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/4e/3ceab890fafff8e78a5fd7f5340c232c38b21d181fcd32d7a31079db3646/powerlaw-1.4.6.tar.gz\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.18.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from powerlaw) (3.2.1)\n",
      "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from powerlaw) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->powerlaw) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->powerlaw) (1.12.0)\n",
      "Building wheels for collected packages: powerlaw\n",
      "  Building wheel for powerlaw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for powerlaw: filename=powerlaw-1.4.6-cp36-none-any.whl size=24787 sha256=09c4fe93c1ef3a6878d76441a896df76d9b97e90d54d4085a26c3efe3f261f3a\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/27/02/08d0e2865072bfd8d7c655e290521e3feca3fc22f1ac460601\n",
      "Successfully built powerlaw\n",
      "Installing collected packages: powerlaw\n",
      "Successfully installed powerlaw-1.4.6\n",
      "time: 4.48 s\n"
     ]
    }
   ],
   "source": [
    "!pip install powerlaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "OOrW3nihw7aP",
    "outputId": "968e9f21-2bf5-462f-92e3-52e9308cad13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /root/.torch/models/resnet164bn_cifar10-0368-74ae9f4b.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.179/resnet164bn_cifar10-0368-74ae9f4b.pth.zip...\n"
     ]
    }
   ],
   "source": [
    "import powerlaw\n",
    "for modelname in pytorchcv.model_provider._models.keys():\n",
    "    if modelname.startswith('resnet') and modelname.endswith('cifar10'):\n",
    "      if modelname == 'resnet164bn_cifar10':\n",
    "        model = ptcv_get_model(modelname, pretrained=True)\n",
    "        Jdiag = jacobian_diagonal(model, train_loader, batch_size)\n",
    "        \n",
    "        results = powerlaw.Fit(Jdiag)\n",
    "        alpha = results.power_law.alpha\n",
    "        print(modelname,alpha)\n",
    "\n",
    "        plt.hist(Jdiag, bins=100, density=True)\n",
    "        plt.title(modelname)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74e2QZn1WP5C"
   },
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZkRjJEzrOIx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-z9FZLDlruJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO1DeSWH7krsAxgosio4TAG",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Jacobians.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02495f41a17b448bbca9e8be8328154c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24d98895f91842deaafef1eb2d6c70cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02495f41a17b448bbca9e8be8328154c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38945f2115b848f78702807a5d42af41",
      "value": 1
     }
    },
    "38945f2115b848f78702807a5d42af41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6c5df6f7e0c84a8d934d85c05d45b4de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f66ac5d1927e46d3a1c8d5aea4ccf788",
      "placeholder": "​",
      "style": "IPY_MODEL_df43ae87ee21434cb56bca9946fa8f92",
      "value": " 170500096/? [00:09&lt;00:00, 17196370.28it/s]"
     }
    },
    "c007b43542fa4ee0890d1659d9382daf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_24d98895f91842deaafef1eb2d6c70cd",
       "IPY_MODEL_6c5df6f7e0c84a8d934d85c05d45b4de"
      ],
      "layout": "IPY_MODEL_d912d31755e74aa8b1c2879b67e49e5e"
     }
    },
    "d912d31755e74aa8b1c2879b67e49e5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df43ae87ee21434cb56bca9946fa8f92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f66ac5d1927e46d3a1c8d5aea4ccf788": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
