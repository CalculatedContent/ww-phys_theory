{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " MLP_randomlabels_10randomcycles_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wozs_tykl-I",
        "colab_type": "code",
        "outputId": "d4fdd9b3-8967-417f-d7ff-1745a3e602a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import math\n",
        "import copy\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_units, init_scale=1.0):\n",
        "    super(MLP, self).__init__()\n",
        "\n",
        "    self._n_units = copy.copy(n_units)\n",
        "    self._layers = []\n",
        "    for i in range(1, len(n_units)):\n",
        "      layer = nn.Linear(n_units[i-1], n_units[i], bias=False)\n",
        "      variance = math.sqrt(2.0 / (n_units[i-1] + n_units[i]))\n",
        "      layer.weight.data.normal_(0.0, init_scale * variance)\n",
        "      self._layers.append(layer)\n",
        "\n",
        "      name = 'fc%d' % i\n",
        "      if i == len(n_units) - 1:\n",
        "        name = 'fc'  # the prediction layer is just called fc\n",
        "      self.add_module(name, layer)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, self._n_units[0])\n",
        "    out = self._layers[0](x)\n",
        "    for layer in self._layers[1:]:\n",
        "      out = F.relu(out)\n",
        "      out = layer(out)\n",
        "    return out\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E1IbTEZm0QQ",
        "colab_type": "code",
        "outputId": "f6abb8b8-16d6-4417-8a3a-1a6f8a116d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/'My Drive'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzBfJfgcmUWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(seed):\n",
        "  normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "  transform_train = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          normalize])\n",
        "  transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize])\n",
        "  train_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=True, \n",
        "                                transform=transform_train,\n",
        "                                download=True)\n",
        "  test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=transform_test,\n",
        "                                download=True)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  probability_of_random = 1.0\n",
        "  labels = np.array(train_dataset.targets) \n",
        "  mask = np.random.rand(len(labels)) <= probability_of_random #create mask of length labels, where entries drawn from [0,1].\n",
        "  rnd_labels = np.random.choice(10, mask.sum())               #create random labels 1-10 of length of mask\n",
        "  labels[mask] = rnd_labels\n",
        "  labels = [int(x) for x in labels]\n",
        "  train_dataset.targets = labels                              #assign new random labels to dataset\n",
        "  \n",
        "  train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=128,\n",
        "                          num_workers=4,\n",
        "                          shuffle=True)\n",
        "  test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=128,\n",
        "                         num_workers=4,\n",
        "                         shuffle=False)\n",
        "  return train_loader, test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97kS66SVmxwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_acc(model, data_loader):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    model.eval()\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "        probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        assert predicted_labels.size() == targets.size()\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rB5iAR1JwAr",
        "colab_type": "code",
        "outputId": "533fa27f-5c81-4300-d75c-1a0a2db2a470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "weights = []\n",
        "models = []\n",
        "\n",
        "for i in range(10):\n",
        "  model = torch.load('MLP_randomlabels_seed' + str(i))\n",
        "  train_loader, test_loader = get_data(i)\n",
        "  \n",
        "  models.append(model)\n",
        "  weights.append(model.fc1.weight)\n",
        "\n",
        "  train_acc = compute_acc(model, train_loader)        \n",
        "  print(f'train ACC: {train_acc:.2f}, seed: {i}')\n",
        "        \n",
        "  test_acc = compute_acc(model, test_loader)        \n",
        "  print(f'Test ACC: {test_acc:.2f}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.28, seed: 0\n",
            "Test ACC: 9.79\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.30, seed: 1\n",
            "Test ACC: 9.83\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.25, seed: 2\n",
            "Test ACC: 10.42\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.22, seed: 3\n",
            "Test ACC: 10.28\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.30, seed: 4\n",
            "Test ACC: 10.17\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.28, seed: 5\n",
            "Test ACC: 10.72\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.28, seed: 6\n",
            "Test ACC: 9.73\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.27, seed: 7\n",
            "Test ACC: 10.01\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.35, seed: 8\n",
            "Test ACC: 10.31\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train ACC: 99.24, seed: 9\n",
            "Test ACC: 9.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLZOYbW_Mt_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norms = []\n",
        "for i in range(10):\n",
        "  for j in range(10):\n",
        "    if i != j:\n",
        "      cross_corr = weights[i] @ weights[j].t()\n",
        "      norms.append(torch.norm(cross_corr, p='fro'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2p4_HPQOIbQ",
        "colab_type": "code",
        "outputId": "151ca774-0dcc-4b33-d734-4ae2492e2e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(norms)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(131.7955, grad_fn=<NormBackward0>), tensor(131.3481, grad_fn=<NormBackward0>), tensor(131.5771, grad_fn=<NormBackward0>), tensor(132.1409, grad_fn=<NormBackward0>), tensor(132.0454, grad_fn=<NormBackward0>), tensor(132.0513, grad_fn=<NormBackward0>), tensor(131.6216, grad_fn=<NormBackward0>), tensor(131.2394, grad_fn=<NormBackward0>), tensor(131.4613, grad_fn=<NormBackward0>), tensor(131.7958, grad_fn=<NormBackward0>), tensor(132.0717, grad_fn=<NormBackward0>), tensor(132.3100, grad_fn=<NormBackward0>), tensor(132.5443, grad_fn=<NormBackward0>), tensor(132.4661, grad_fn=<NormBackward0>), tensor(132.5544, grad_fn=<NormBackward0>), tensor(132.2428, grad_fn=<NormBackward0>), tensor(131.3037, grad_fn=<NormBackward0>), tensor(131.7107, grad_fn=<NormBackward0>), tensor(131.3471, grad_fn=<NormBackward0>), tensor(132.0721, grad_fn=<NormBackward0>), tensor(132.0779, grad_fn=<NormBackward0>), tensor(132.7404, grad_fn=<NormBackward0>), tensor(132.3577, grad_fn=<NormBackward0>), tensor(132.4270, grad_fn=<NormBackward0>), tensor(131.9241, grad_fn=<NormBackward0>), tensor(131.6401, grad_fn=<NormBackward0>), tensor(131.6659, grad_fn=<NormBackward0>), tensor(131.5773, grad_fn=<NormBackward0>), tensor(132.3095, grad_fn=<NormBackward0>), tensor(132.0778, grad_fn=<NormBackward0>), tensor(132.8502, grad_fn=<NormBackward0>), tensor(132.5655, grad_fn=<NormBackward0>), tensor(132.9339, grad_fn=<NormBackward0>), tensor(131.9929, grad_fn=<NormBackward0>), tensor(131.6048, grad_fn=<NormBackward0>), tensor(132.0365, grad_fn=<NormBackward0>), tensor(132.1410, grad_fn=<NormBackward0>), tensor(132.5441, grad_fn=<NormBackward0>), tensor(132.7403, grad_fn=<NormBackward0>), tensor(132.8495, grad_fn=<NormBackward0>), tensor(132.9173, grad_fn=<NormBackward0>), tensor(133.2832, grad_fn=<NormBackward0>), tensor(132.8084, grad_fn=<NormBackward0>), tensor(132.1122, grad_fn=<NormBackward0>), tensor(132.2644, grad_fn=<NormBackward0>), tensor(132.0457, grad_fn=<NormBackward0>), tensor(132.4664, grad_fn=<NormBackward0>), tensor(132.3566, grad_fn=<NormBackward0>), tensor(132.5643, grad_fn=<NormBackward0>), tensor(132.9170, grad_fn=<NormBackward0>), tensor(133.0772, grad_fn=<NormBackward0>), tensor(132.5046, grad_fn=<NormBackward0>), tensor(131.7957, grad_fn=<NormBackward0>), tensor(132.3907, grad_fn=<NormBackward0>), tensor(132.0517, grad_fn=<NormBackward0>), tensor(132.5552, grad_fn=<NormBackward0>), tensor(132.4280, grad_fn=<NormBackward0>), tensor(132.9333, grad_fn=<NormBackward0>), tensor(133.2826, grad_fn=<NormBackward0>), tensor(133.0778, grad_fn=<NormBackward0>), tensor(132.7549, grad_fn=<NormBackward0>), tensor(132.3399, grad_fn=<NormBackward0>), tensor(132.6101, grad_fn=<NormBackward0>), tensor(131.6207, grad_fn=<NormBackward0>), tensor(132.2422, grad_fn=<NormBackward0>), tensor(131.9236, grad_fn=<NormBackward0>), tensor(131.9937, grad_fn=<NormBackward0>), tensor(132.8089, grad_fn=<NormBackward0>), tensor(132.5045, grad_fn=<NormBackward0>), tensor(132.7557, grad_fn=<NormBackward0>), tensor(131.5946, grad_fn=<NormBackward0>), tensor(132.2005, grad_fn=<NormBackward0>), tensor(131.2402, grad_fn=<NormBackward0>), tensor(131.3036, grad_fn=<NormBackward0>), tensor(131.6407, grad_fn=<NormBackward0>), tensor(131.6046, grad_fn=<NormBackward0>), tensor(132.1125, grad_fn=<NormBackward0>), tensor(131.7962, grad_fn=<NormBackward0>), tensor(132.3383, grad_fn=<NormBackward0>), tensor(131.5947, grad_fn=<NormBackward0>), tensor(131.6868, grad_fn=<NormBackward0>), tensor(131.4613, grad_fn=<NormBackward0>), tensor(131.7118, grad_fn=<NormBackward0>), tensor(131.6662, grad_fn=<NormBackward0>), tensor(132.0371, grad_fn=<NormBackward0>), tensor(132.2639, grad_fn=<NormBackward0>), tensor(132.3918, grad_fn=<NormBackward0>), tensor(132.6106, grad_fn=<NormBackward0>), tensor(132.2008, grad_fn=<NormBackward0>), tensor(131.6860, grad_fn=<NormBackward0>)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}